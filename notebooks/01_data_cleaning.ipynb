import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Download NLTK resources (only first time)
nltk.download('stopwords')
nltk.download('wordnet')

# Load your CSV
csv_path = r"C:\Users\Brindha Suvarna R\Desktop\sentiment-classifier\data\raw\review.csv"
df = pd.read_csv(csv_path)

# Initialize tools
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

# Cleaning function
def clean_text(text):
    text = str(text).lower()  # lowercase
    text = re.sub(r'[^\w\s]', '', text)  # remove punctuation
    text = re.sub(r'\s+', ' ', text).strip()  # remove extra spaces
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]  # remove stopwords
    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # lemmatize
    return ' '.join(tokens)

# Apply cleaning
df['cleaned_review'] = df['review'].apply(clean_text)

# Drop any rows where review or sentiment is missing
df = df.dropna(subset=['cleaned_review', 'sentiment']).reset_index(drop=True)

# Save cleaned data
df.to_csv(r"C:\Users\Brindha Suvarna R\Desktop\sentiment-classifier\data\processed\cleaned_reviews.csv", index=False)

print("Data cleaning completed. Cleaned CSV saved.")
